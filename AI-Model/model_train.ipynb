{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7ba0d-d854-4414-a0af-865fa5a3cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936f32d-64dd-4ece-a6ee-584292f66ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames loaded, cleaned, transformed, and labels prepared successfully!\n",
      "Train samples: 2214. First 5 rows of the transformed data:\n",
      "                                            filename is_disease\n",
      "0     15_jpg.rf.b8a6d4c751dd3da5c62861bff997124c.jpg          1\n",
      "1  0016_0P_-10H_10V_png_jpg.rf.b76aa8767452ebb6f3...          0\n",
      "2  F_1061_jpg.rf.b777e4afeededd6a5f6a484c2b4029b6...          1\n",
      "3  images-6_jpeg_jpg.rf.b98a56b0f762e602fccfb9813...          1\n",
      "4  images-12-_jpeg_jpg.rf.b7f535c63943e5c62b2b97b...          1\n"
     ]
    }
   ],
   "source": [
    "# --- Model Constants ---\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 1\n",
    "BASE_LR = 1e-4\n",
    "FINE_TUNE_LR = 1e-5\n",
    "\n",
    "# --- UPDATE THESE PATHS ---\n",
    "DATA_DIR = 'C:\\\\Users\\\\adith\\\\Downloads\\\\Eye-Cancer\\\\Dataset\\\\' \n",
    "TRAIN_CSV = f'{DATA_DIR}train\\\\train.csv' \n",
    "VALID_CSV = f'{DATA_DIR}valid\\\\valid.csv'\n",
    "TEST_CSV = f'{DATA_DIR}test\\\\test.csv'\n",
    "\n",
    "# --- FIXED COLUMN NAMES ---\n",
    "IMAGE_COL = 'filename'\n",
    "# The new calculated binary column name\n",
    "LABEL_COL = 'is_disease'\n",
    "\n",
    "# These names are assumed to be correct AFTER stripping whitespace.\n",
    "DISEASE_COLUMNS = ['bulging_eyes', 'cataracts', 'crossed_eyes', 'uveitis']\n",
    "\n",
    "\n",
    "def create_binary_target(df):\n",
    "    \"\"\"Calculates a new binary target column 'is_disease'.\"\"\"\n",
    "    # Sum the '1's across all disease columns for each row\n",
    "    df['total_disease'] = df[DISEASE_COLUMNS].sum(axis=1)\n",
    "    \n",
    "    # If the sum is > 0, the eye is diseased (1). Otherwise, it's considered non-diseased (0).\n",
    "    df[LABEL_COL] = np.where(df['total_disease'] > 0, 1, 0)\n",
    "    \n",
    "    # Drop the temporary column and the original disease columns\n",
    "    df = df.drop(columns=['total_disease'] + DISEASE_COLUMNS + ['normal_eyes'])\n",
    "    return df\n",
    "\n",
    "# --- Load and Transform DataFrames ---\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    valid_df = pd.read_csv(VALID_CSV)\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    \n",
    "    # CRITICAL FIX: Strip whitespace from all column names immediately after loading\n",
    "    train_df.columns = train_df.columns.str.strip()\n",
    "    valid_df.columns = valid_df.columns.str.strip()\n",
    "    test_df.columns = test_df.columns.str.strip()\n",
    "    \n",
    "    # Transform all three datasets using the clean column names\n",
    "    train_df = create_binary_target(train_df)\n",
    "    valid_df = create_binary_target(valid_df)\n",
    "    test_df = create_binary_target(test_df)\n",
    "    \n",
    "    # Convert the new binary column to string for Keras's flow_from_dataframe\n",
    "    train_df[LABEL_COL] = train_df[LABEL_COL].astype(str)\n",
    "    valid_df[LABEL_COL] = valid_df[LABEL_COL].astype(str)\n",
    "    test_df[LABEL_COL] = test_df[LABEL_COL].astype(str)\n",
    "    \n",
    "    print(\"DataFrames loaded, cleaned, transformed, and labels prepared successfully!\")\n",
    "    print(f\"Train samples: {len(train_df)}. First 5 rows of the transformed data:\\n{train_df.head()}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"CRITICAL ERROR: File not found. Please check your file paths in Cell 1: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"CRITICAL ERROR: A column was not found after cleaning. Please verify the spelling of columns in DISEASE_COLUMNS: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183ca0a-2bd7-4b28-9775-5b08dc286cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data Generators...\n",
      "Found 2214 validated image filenames belonging to 2 classes.\n",
      "Found 363 validated image filenames belonging to 2 classes.\n",
      "Found 100 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Constants from previous successful cell ---\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# **Crucial:** Ensure this matches your IMAGE_FOLDER_BASE variable exactly from the previous successful cell.\n",
    "IMAGE_FOLDER_BASE = 'C:\\\\Users\\\\adith\\\\Downloads\\\\Eye-Cancer\\\\Dataset\\\\' \n",
    "IMAGE_COL = 'filename'\n",
    "LABEL_COL = 'is_disease'\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "print(\"Initializing Data Generators...\")\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=f'{IMAGE_FOLDER_BASE}train\\\\',\n",
    "        x_col=IMAGE_COL,\n",
    "        y_col=LABEL_COL,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    valid_generator = valid_test_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=f'{IMAGE_FOLDER_BASE}valid\\\\',\n",
    "        x_col=IMAGE_COL,\n",
    "        y_col=LABEL_COL,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    test_generator = valid_test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=f'{IMAGE_FOLDER_BASE}test\\\\',\n",
    "        x_col=IMAGE_COL,\n",
    "        y_col=LABEL_COL,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False # CRITICAL: Keep test images in order for final evaluation\n",
    "    )\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nCRITICAL ERROR: Image files not found. Please verify the directory path: {e}\")\n",
    "    print(\"Ensure the folders 'train', 'valid', and 'test' containing the actual JPG/PNG images are located correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212dded-c50e-43a2-b09a-bda8a38d1844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ResNet50 Base Model...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n",
      "\n",
      "Model Summary (Before Training):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m513\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,637,313</span> (93.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,637,313\u001b[0m (93.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,601</span> (4.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,049,601\u001b[0m (4.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Model Constants from previous successful cell ---\n",
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# --- Load the Pre-trained ResNet50 Base Model ---\n",
    "print(\"Building ResNet50 Base Model...\")\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    ")\n",
    "\n",
    "# 2. Freeze the base layers for Phase 1\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Define the Custom Classification Head (Your binary classifier)\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"\\nModel Summary (Before Training):\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad92ff-ae34-46c8-8894-64340e0e581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Phase 1: Training Classification Head (10 Epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8233 - loss: 0.3786 - sensitivity_at_90_specificity: 0.6368 - specificity_at_90_sensitivity: 0.5509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.9102 - loss: 0.2120 - sensitivity_at_90_specificity: 0.8554 - specificity_at_90_sensitivity: 0.8418 - val_accuracy: 0.9858 - val_loss: 0.0474 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m 1/69\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 970ms/step - accuracy: 0.9375 - loss: 0.1212 - sensitivity_at_90_specificity: 0.9500 - specificity_at_90_sensitivity: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 151ms/step - accuracy: 0.9375 - loss: 0.1212 - sensitivity_at_90_specificity: 0.9500 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9858 - val_loss: 0.0454 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9716 - loss: 0.0805 - sensitivity_at_90_specificity: 0.9882 - specificity_at_90_sensitivity: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.9757 - loss: 0.0705 - sensitivity_at_90_specificity: 0.9926 - specificity_at_90_sensitivity: 0.9928 - val_accuracy: 0.9915 - val_loss: 0.0247 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 205ms/step - accuracy: 0.9688 - loss: 0.0449 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9886 - val_loss: 0.0248 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9866 - loss: 0.0481 - sensitivity_at_90_specificity: 0.9967 - specificity_at_90_sensitivity: 0.9936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.9830 - loss: 0.0473 - sensitivity_at_90_specificity: 0.9949 - specificity_at_90_sensitivity: 0.9976 - val_accuracy: 0.9943 - val_loss: 0.0189 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0114 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9943 - val_loss: 0.0194 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9865 - loss: 0.0357 - sensitivity_at_90_specificity: 0.9997 - specificity_at_90_sensitivity: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.9867 - loss: 0.0360 - sensitivity_at_90_specificity: 0.9994 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0132 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0081 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0129 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.9895 - loss: 0.0280 - sensitivity_at_90_specificity: 0.9983 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0106 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0235 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0105 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- Model Constants from previous successful cell ---\n",
    "BASE_LR = 1e-4 # Learning rate for Phase 1\n",
    "FINE_TUNE_LR = 1e-5 # Learning rate for Phase 2\n",
    "\n",
    "# Define callbacks for saving the best model and stopping if performance plateaus\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_eye_cancer_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=BASE_LR),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "              tf.keras.metrics.SensitivityAtSpecificity(0.9, name='sensitivity_at_90_specificity'),\n",
    "              tf.keras.metrics.SpecificityAtSensitivity(0.9, name='specificity_at_90_sensitivity')]\n",
    ")\n",
    "\n",
    "print(\"\\n--- Starting Phase 1: Training Classification Head (10 Epochs) ---\")\n",
    "# Use the generators created in Step 3\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=10,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678593bf-ab46-435e-b1cf-6666df8cab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Phase 2: Fine-Tuning Entire Model (Up to 50 Epochs) ---\n",
      "Epoch 1/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.9913 - loss: 0.0321 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 0.9952 - val_accuracy: 0.9972 - val_loss: 0.0116 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0267 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0115 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0190 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0102 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0067 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0104 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0162 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0066 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0027 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0066 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0071 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0066 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0039 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0064 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9986 - loss: 0.0079 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0060 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0033 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0065 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0048 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0071 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0120 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0070 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.9991 - loss: 0.0041 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0057 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 6.0636e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0058 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0040 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0057 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 4.4754e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0054 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9991 - loss: 0.0032 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0050 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0011 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0050 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0030 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0055 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 3.8239e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0055 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0017 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0062 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 3.1732e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0063 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0012 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0012 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.4405e-04 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 0.0012 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0062 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0013 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0063 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 3.7158e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0063 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0020 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0059 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0013 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0058 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0014 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0056 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 5.1585e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0056 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.3365e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0072 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 4.0229e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0072 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 5.7485e-04 - sensitivity_at_90_specificity: 1.0000 - specificity_at_90_sensitivity: 1.0000 - val_accuracy: 0.9972 - val_loss: 0.0070 - val_sensitivity_at_90_specificity: 1.0000 - val_specificity_at_90_sensitivity: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 1. Unfreeze Top Layers\n",
    "base_model = model.layers[0] # Get the ResNet50 layer object\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the last 20 to focus fine-tuning on relevant features\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 2. Re-compile the model with a tiny learning rate for careful weight adjustment\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "              tf.keras.metrics.SensitivityAtSpecificity(0.9, name='sensitivity_at_90_specificity'),\n",
    "              tf.keras.metrics.SpecificityAtSensitivity(0.9, name='specificity_at_90_sensitivity')]\n",
    ")\n",
    "\n",
    "print(\"\\n--- Starting Phase 2: Fine-Tuning Entire Model (Up to 50 Epochs) ---\")\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=50,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241e3c7-508e-417c-9e91-b638283d4fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trained model loaded successfully.\n",
      "Generating predictions on the Test Set...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step\n",
      "\n",
      "--- Final Model Performance on Test Set ---\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        21\n",
      "           1     1.0000    1.0000    1.0000        79\n",
      "\n",
      "    accuracy                         1.0000       100\n",
      "   macro avg     1.0000    1.0000    1.0000       100\n",
      "weighted avg     1.0000    1.0000    1.0000       100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21  0]\n",
      " [ 0 79]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# --- Re-using variables from successful steps ---\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_COL = 'filename'\n",
    "LABEL_COL = 'is_disease'\n",
    "\n",
    "# 1. Load the Best Model\n",
    "try:\n",
    "    best_model = tf.keras.models.load_model('best_eye_cancer_model.h5')\n",
    "    print(\"Best trained model loaded successfully.\")\n",
    "    \n",
    "except OSError:\n",
    "    print(\"CRITICAL ERROR: Model file not found. Ensure training finished successfully and 'best_eye_cancer_model.h5' was created.\")\n",
    "\n",
    "# 2. Get True Labels\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# 3. Get Predicted Probabilities\n",
    "steps = int(np.ceil(test_generator.samples / BATCH_SIZE))\n",
    "print(\"Generating predictions on the Test Set...\")\n",
    "y_pred_proba = best_model.predict(test_generator, steps=steps)\n",
    "\n",
    "# 4. Convert probabilities to binary classes using a 0.5 threshold\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Get the class names ('0' and '1') for the report\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\n--- Final Model Performance on Test Set ---\")\n",
    "\n",
    "# Detailed Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
